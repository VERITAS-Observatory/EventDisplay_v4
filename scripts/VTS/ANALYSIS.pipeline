#!/bin/bash
CWD=$PWD
########################################
#
# Written by Nathan Kelley-Hoskins
# Feb 2013
#

########################################################
# HOW DO I USE THIS ?                                  #
# put this in a new directory,                         #
# add your runlist file to that directory,             #
# edit the settings below, then use the commands       #
# $ ANALYSIS.pipeline [evndisp|mscw|anpar|anmer]       #
# to run stages of the analysis,                       #
# $ ANALYSIS.pipeline jobs                             #
# to see currently running jobs, and                   #
# $ ANALYSIS.pipeline [evndisp|mscw|anpar|anmer] check #
# to check the results of each stage for errors        #
########################################################

#############################################################################
#
# Syntax rules for the below section:
#   1. lines that begin with 'export' are the options
#   2. lines that start with '#%' are special properties read in by the 
#      options browser parser, and ignored by the print-to-terminal parser
#   3. in the options-browser parser, empty lines will reset all option properties
#
# // do not change the stuff in the square brackets in the next line, it is needed for the 'options' keyword
# [BEGIN ANALYSIS SETTINGS 3823984]

## Which Runlist file should we use?
#% GroupName Runlist Filename
#% ActiveStage evndisp
#% OptionComplexity Common
#% Description Which runlist file should be used?  One runnumber per line.
# Which runlist do you want to use?
# It should be a simple list of veritas runnumbers,
# one per line.  Used in all stages.
# (full path please)
#% OptionArgType full path
export RUNLIST="$CWD/runlist.crab.dat"

## Should we use the TMVA-BDTs feature?
#% GroupName TMVABDT Feature
#% ActiveStage anpar
#% OptionComplexity Common
#% Description Should the TMVA-BDTs feature be used?
# use TMVA-BDT feature(yes/no)
# takes effect in the anpar stage
#% OptionArgType yes|no
export USETMVABDT="no"
#% OptionComplexity Common
#% Description Should the TMVA-BDT weak cuts feature be used?
#% OptionArgType yes|no
export USETMVABDTWEAK="no"

## Should we use the Model3D feature?
#% GroupName Model3D Feature
#% ActiveStage model3d
#% OptionComplexity Uncommon
#% Description Should the Model3D feature be used?  (Warning: ot fully implemented yet)
# use Model3D feature(yes/no)
# Takes effect in the evndisp stage.
#% OptionArgType yes|no
export USEMODEL3D="no"

## Should we use the Energy3D feature?
#% GroupName Energy3D Feature
#% ActiveStage energy3d
#% OptionComplexity Uncommon
#% Description Should the Energy3D feature be used?
## This feature is not *yet* functional, contact
## nils for more information.
# takes effect in the mscw stage.
#% OptionArgType yes|no
export USEENERGY3D="no"

## What kind of cuts do you want to use?
#% GroupName Energy Cuts
#% ActiveStage anpar
#% OptionComplexity Common
#% Description What kind of energy cuts should be used?<br>Soft will have higher sensitivity to low-energy events,<br>while Hard will have higher sensitivity to high-energy events.
# Currently supports:
#    'Soft', 'Moderate', 'Hard', 
#    'SoftOpen', 'ModerateOpen', 'SuperHard'
# Takes effect in the anpar stage.
#% OptionArgType Soft|Moderate|Hard
export CUTS="Moderate"

## What kind of background do you want to use?
#% GroupName Anasum Background Type
#% ActiveStage anpar
#% OptionComplexity Common
#% Description Do you want to use the ring or the reflected region background method?
# 'ring' or 'refl' (for reflected)
# Takes effect in the anpar stage.
#% OptionArgType ring|(refl|reflect|reflected)
export BACKGROUND="refl"
#
# If using the 'ring' background method:
# How how big should the radius of the the 'on' region be, in degrees?
#% Description How big should the radius of the 'on' region be, in degrees?
#% OptionArgType float
export RINGCENT="0.5"
# and how big should the 'off' ring be, in units of 'on'-region areas?
#% Description How big should the 'off' ring be, in units of on-region-areas (when using the Ring Background method).
#% OptionArgType integer
export RINGAREA="10"
#
# If using the reflected(refl) background method:
# what should be the minimum distance between off region edges, in degrees?
#% Description Minimum distance between region edges when using the Reflected region background method.
#% OptionArgType float
export REFLWOBOFF="0.5"
# whats the minimum number of off regions we require?
#% Description Minimum number of regions required when using the Reflected region background method.
#% OptionArgType integer
export REFLMINREG="1"
# and the maximum number of off regions we require?
#% Description Maximum number of regions required when using the Reflected region background method.
#% OptionArgType integer
export REFLMAXREG="10"

## Should we produce the tzero and pedestal files first?
#% GroupName Process Calibration Files
#% ActiveStage evndisp
#% OptionComplexity Common
#% Description Should the tzero and pedestal files be generated?
# These are required to do an analysis.
# Takes effect in the evndisp stage.
# yes/no
#% OptionArgType yes|no
export DOCALIB=yes

## Where should we store the evndisp and mscw output files?
#% ActiveStage evndisp
#% OptionComplexity Uncommon
#% GroupName MSCW Output File Storage Directory
#% Description Where we should store the evndisp and mscw output files.
# Takes effect in the evndisp stage.
# (full path please)
# evndisp files will be: $EVNDISPOUTPUTDIR/#####.root, #####.tzero.root, etc
# mscw files will be put in RecIDX within this directory (see next option)
#% OptionArgType full path
export EVNDISPOUTPUTDIR="$VERITAS_USER_DATA_DIR/analysis/Results/EVD-v423/"

## Which Reconstruction ID (RecID) should we use?
#% GroupName MSCW Telescope Exclusion
#% ActiveStage mscw
#% OptionComplexity Uncommon
#% Description Do we want to exclude any telescopes images when analysing the mscw stage?<br>0=normal, 1=exlclude T1 images, 2=exclude T2 images, etc.<br>For regular data analysis, this should be 0.
# 0, 1, 2, 3, or 4
# 0 = do mscw stage with all available images
# 1 = do mscw stage without using T1 images
# 2 = do mscw stage without using T2 images
# 3 = do mscw stage without using T3 images
# 4 = do mscw stage without using T4 images
# Takes effect in the mscw stage.
## For regular data analysis, this should be 0
#% OptionArgType 0|1|2|3|4
export RECID=0

## Should we use the frogs feature?
#% GroupName Frogs Feature
#% ActiveStage frogs
#% OptionComplexity Uncommon
#% Description Should we use the frogs feature?
# In the anasum stage, should we use frogs datafiles as the input?
# If no, we will use the mscw datafiles instead.
# To create the frogs datafiles, just run the 'frogs' stage.
## Attention: To use this feature properly, after the 'mscw' stage, 
## you must run the 'frogs' stage for this option to fully take effect.
# yes/no
#% OptionArgType yes|no
export USEFROGS="no"

## Where should the frogs's output files be stored?
#% GroupName Frogs Output File Storage Directory
#% ActiveStage frogs
#% OptionComplexity Uncommon
#% Description Directory for storing the frogs output files.
# Takes effect in the frogs stage.
# (full path please)
#% OptionArgType full path
export FROGSOUTPUTDIR="$EVNDISPOUTPUTDIR/frogs"

## Where should we put the anasum output files (parallel and merged)?
#% GroupName Anasum Parallel Output File Storage Directory
#% ActiveStage anpar
#% OptionComplexity Uncommon
#% Description Directory for storing the anasum parallel output files.
# Takes effect in the anpar stage.
# (full path please)
#% OptionArgType full path
export ANASUMOUTPUTDIR="$CWD/arf"

## What should we name the final merged anasum
#% GroupName Merged Anasum Filename
#% ActiveStage anmer
#% OptionComplexity Common
#% Description What should we name our final merged anasum root file?  Will be overwritten by 'anmer' stage if it exsts.
# output root file? It will be put in $ANASUMOUTPUTDIR
# Takes effect in the anmer stage.
# Filename only, not full path.
#% OptionArgType filename within project dir (not full path)
export FINALOUTPUT="anmer.output.root"

## Which anasum runparameter file should we use?
#% GroupName Anasum Runparameter File
#% ActiveStage anpar
#% OptionComplexity Uncommon
#% Description Which anasum runparameter file should be used?
# Takes effect in the anpar stage.
# (full path please)
#% OptionArgType full path
export RUNPARAMFILE="$VERITAS_EVNDISP_AUX_DIR/ParameterFiles/ANASUM.runparameter"

## Which event display reconstruction runparameter file should we use?
# CA is for runs that use CARE-derived IRFs
# GR is for runs that use GRISU-derived IRFs
#% GroupName evndisp reconstruction runparameter file
#% ActiveStage evndisp
#% OptionComplexity Uncommon
#% OptionArgType filename within $VERITAS_EVNDISP_AUX_DIR/ParameterFiles
#% Description Which reconstruction file should we use with care-derived irf files?
export EVNRECONFILE_CA="EVNDISP.reconstruction.runparameter"
#% Description Which reconstruction file should we use with grisu-derived irf files?
export EVNRECONFILE_GR="EVNDISP.reconstruction.SumWindow-noDISP"

## Do you want to automatically generate the anasum runlist? (recommended)
#% GroupName Auto-generate Anasum Runlist
#% ActiveStage anpar
#% OptionComplexity Uncommon
#% Description Should the anasum runlist be automatically generated? (recommended)
# If so, leave ANRUNLIST blank
# If you want to use your own anasum runlist, put the full path to your
# custom anasum runlist here.
#% OptionArgType full path
export ANRUNLIST=""

## For the Effective Area and Radial Acceptance Files, whats the minimum
## number of telescopes we require?
#% GroupName Minimum Number of Telescopes
#% ActiveStage anpar
#% OptionComplexity Uncommon
#% Description For the IRF files, whats the minimum number of telescopes we require?
# Should be 2, 3, or 4.
#% OptionArgType 2|3|4
export AUXFILE_MINTEL="2"

## Are we analysing a point source, or an extended source?
#% GroupName Source Extension
#% ActiveStage anpar
#% Description Are we analysing a point source, or an extended source?
#% OptionComplexity Uncommon
# The Effective Area file depends on this setting.
# Either 'PointSource' or 'ExtendedSource'
#% OptionArgType PointSource|ExtendedSource
export AUXFILE_SRCEXT="PointSource"

## Do you want to use the DISP feature?
#% GroupName Disp Feature
#% ActiveStage evndisp
#% OptionComplexity Uncommon
#% Description Should we use the DISP feature? (improved shower image intersection reconstruction)
# This will change how image axes and their intersection
# are handled.
# (yes/no)
#% OptionArgType yes|no
export SCIPIPE_USEDISP="no"

## For your Effective Area, Radial Acceptance, and Table IRF files:
#% GroupName Auxillary File Preferences
#% ActiveStage mscw
#% OptionComplexity Uncommon
#% Description Which event display version's aux files should be used.  Older version auxfiles  may not be compatible with current release. <br>(effArea-<b>v481</b>-auxv01-CARE_June1425-Cut-NTel2-PointSource-SoftOpen-ID0-V6-ATM21-T1234.root)
#
# Which event display version should they have been made with?
# e.g. effArea-v481-auxv01-CARE_June1425-Cut-NTel2-PointSource-SoftOpen-ID0-V6-ATM21-T1234.root
#              ^^^^
# radialAcceptance-v481-auxv01-Cut-NTel2-ExtendedSource-Hard-ID0-V6-T1234.root
#                  ^^^^
# table-v481-auxv01-CARE_June1425-ATM21-V6-ID0.root
#       ^^^^
# Should have the format 'v###', like 'v481' or 'v525', etc.
#% OptionArgType v###
export AUXFILE_EVNVER="v481"
#
#% Description Which simulation files should be used? <br>(effArea-v481-auxv01-<b>CARE_June1425</b>-Cut-NTel2-PointSource-SoftOpen-ID0-V6-ATM21-T1234.root)
# Which simulation date should they have been made with?
# Grisu is used for all V4/V5 runs, and CARE is used for V6 runs.
# e.g. effArea-v481-auxv01-CARE_June1425-Cut-NTel2-PointSource-SoftOpen-ID0-V6-ATM21-T1234.root
#                          ^^^^^^^^^^^^^
# for Care (_CA), Should have the format '<simtype>_<month><year><day>', like 'CARE_June1425' 
# for Grisu(_GR), just 'GRISU-SW6'
#% OptionArgType simdatestring
export AUXFILE_SIMDATE_GR="GRISU-SW6"
export AUXFILE_SIMDATE_CA="CARE_June1425"
#
#% Description Aux file version to try to use for Radial Acceptance files.<br>(radialAcceptance-v481-<b>auxv01</b>-Cut-NTel2-ExtendedSource-Hard-ID0-V6-T1234.root)
# For the radial acceptance IRF file, what aux-file-version should be used?
# e.g. radialAcceptance-v481-auxv01-Cut-NTel2-ExtendedSource-Hard-ID0-V6-T1234.root
#                            ^^^^^^
# Should have the format 'auxv##', e.g. 'auxv01' or 'auxv31'
#% OptionArgType auxv##
export AUXVER_RADEC="auxv01"
#
#% Description Aux file version to try to use for Table files.<br>(table-v481-<b>auxv01</b>-CARE_June1425-ATM21-V6-ID0.root)
# For the table IRF file, what aux-file-version should be used?
# e.g. table-v481-auxv01-CARE_June1425-ATM21-V6-ID0.root
#                 ^^^^^^
# Should have the format 'auxv##', e.g. 'auxv01' or 'auxv31'
#% OptionArgType auxv##
export AUXVER_TABLE="auxv01"
#
#% Description Aux file version to try to use for Effective Area Files.<br>(effArea-v481-<b>auxv01</b>-CARE_June1425-Cut-NTel2-PointSource-SoftOpen-ID0-V6-ATM21-T1234.root)
# For the effective area IRF file, what aux-file-version should be used?
# e.g. effArea-v481-auxv01-CARE_June1425-Cut-NTel2-PointSource-SoftOpen-ID0-V6-ATM21-T1234.root
#                   ^^^^^^
# Should have the format 'auxv##', e.g. 'auxv01' or 'auxv31'
#% OptionArgType auxv##
export AUXVER_EFFAREA="auxv01"

## Which directory should we keep any ctools datafiles we produce with the 'mutate' command?
#% GroupName ctools
#% ActiveStage mutate
#% OptionComplexity Uncommon
#% OptionArgType full path
#% Description Directory for storing output ctools fits files.
# Takes effect in the mutate stage.
export CTOOLSDIR="$CWD/ctoolsdata"

## To scan the logfiles for custom keywords:
#% GroupName Logfile Search String
#% ActiveStage evndisp
#% OptionComplexity Developer
#% OptionArgType string|regex
#% Description During any 'ANALYSIS.pipeline * check' command, also search for any lines that contain SCIPIPE_DEBUGREGEX, for easier debugging.
# any lines matching $SCIPIPE_DEBUGREGEX will be
# shown in blue when 'check'ing stages
# It is a regex pattern(google it), 
# e.g. "NKH|WHITEBOARD" will highlight any 
# logfile lines containing "NKH" or "WHITEBOARD" .
# It is used as a Perl-style Regex, aka:
#   $ grep -P $SCIPIPE_DEBUGREGEX logfilename
# This will work in addition to the warning and
#   error scanning.
export SCIPIPE_DEBUGREGEX="WHITEBOARD"

## To only process the first X events:
#% GroupName Only Process X Events
#% ActiveStage evndisp
#% OptionComplexity Developer
#% OptionArgType integer
#% Description Only process the first SCIPIPE_NEVENTS events, for fast code development/testing/debugging.  Obviously, this will not produce good science.  Set to "" for normal operation.
# if set to an integer X, some stages (evndisp,frogs) 
# will only run for the first X events,
# to allow for very fast testing and debugging.
# Do not use this option and expect good science!
export SCIPIPE_NEVENTS=""

## If you want the pipeline to not use colored text:
#% GroupName Terminal Coloring Options
#% ActiveStage evndisp
#% OptionComplexity Uncommon
#% OptionArgType nooptions|nologs|nooptions:nologs
#% Description Disable color output of terminal text.<br>nooptions for boring colors with 'ANALYSIS.pipeline options',<br>nologs for boring colors in any 'check' command,<br> or both.
# you can use the SCIPIPE_COLOROPT environment variable.
# To only turn off colors in the command $ ANALYSIS.pipeline options, (or 'settings') use
# export SCIPIPE_COLOROPT="nooptions"
# To only turn off colors in the output of the stage 'check's, use 
# export SCIPIPE_COLOROPT="nologs"
# To turn off both, use 
# export SCIPIPE_COLOROPT="nooptions:nologs"
export SCIPIPE_COLOROPT=""

## Should we use manually-defined laser runs for some runs?
#% GroupName Laser Run Designatiion
#% ActiveStage evndisp
#% OptionComplexity Uncommon
#% OptionArgType yes|no
#% Description For manually defining which laser runs to use with which data runs.  no=automatic,<br>yes=use runnumber-lasernumber file specified by SCIPIPE_MANUALLASERFILE .
# Takes effect in the evndisp stage.
# (yes/no)
export SCIPIPE_MANUALLASER="no"
# If yes, which calibration file should we use to manually define 
# which runs have which laser runs?
# The calibration file should be in $VERITAS_EVNDISP_AUX_DIR/Calibration ,
# and should have the same format as calibrationlist.dat in that directory.
#% OptionArgType filename within $VERITAS_EVNDISP_AUX_DIR/Calibration/
#% Description If SCIPIPEMANUALLASER=yes, then use this file for picking which laser runs to use.
export SCIPIPE_MANUALLASERFILE="calibrationlist.dat"

## The above options should be put into a separate config 
## file 'analysis.config' to override the above default settings.
# A blank 'analysis.config' file can be created via:
#   $ ANALYSIS.pipeline newconfig
# This config file should be in the same directory as the 
#   ANALYSIS.pipeline script (or a link to the pipeline).
# The config file is a 'bash' script, obeying all 'bash' syntax.
# These options must each be preceded by 'export', like so:
# export RUNLIST="$CWD/runlist.cygnus.dat"
# export BACKGROUND="refl"
# export REFLWOBOFF="0.8"
# export CUTS="soft"


# [END ANALYSIS SETTINGS 843230239] 
# // do not change the line above,
# // doing so will interfere with the 'options' keyword
# // the number is random so the regex doesn't match itself
#
###########################################################################################


ANAPIPENAME="$0"
if [[ $# < 1 || ! $1 =~ (evndisp|mscw|frogs|anpar|anmer|mutate|options|options_browser|settings|newconfig|jobs|kill|xxf) ]] ; then 
    echo "
HOW DO I USE THIS ?                             

   1. Make a project directory, and make a soft link to \$EVNDISPSYS/scripts/VTS/ANALYSIS.pipeline, via
      $ ln -s \$EVNDISPSYS/scripts/VTS/ANALYSIS.pipeline

   2. Add your runlist file to your project directory

   3. Create a new analysis config file 'analysis.config' in your project directory:
      $ ./$ANAPIPENAME newconfig

   4. View all the options you can add to 'analysis.config':
      $ ./$ANAPIPENAME options
	
   5. Add your runlist filename and any options to your 'analysis.config'.
      Options should have the same format as in a bash file:

      export RUNLIST=crab.runlist
      export CUTS="Moderate"

      etc.

   6. Run a stage of the analysis:
		
        i) Submit stage jobs to the cluster:
        $ $ANAPIPENAME [evndisp|mscw|frogs|anpar|anmer|mutate]                
		
        ii) Check if jobs are done:
        $ $ANAPIPENAME jobs
		
        iii) Check the results of the stage for errors
        $ $ANAPIPENAME [evndisp|mscw|frogs|anpar|anmer|mutate] check
		

Stages of Event Display: [evndisp|mscw|frogs|anpar|anmer],
  (optional 'check' afterwards)
  $ $ANAPIPENAME evndisp         # run the 'event display' stage
  $ $ANAPIPENAME evndisp check   # after evndisp, check its log and datafiles for problems
  $ $ANAPIPENAME mscw            # run the 'mean scaled width' stage
  $ $ANAPIPENAME mscw check      # after mscw, check its log and datafiles for problems
  $ $ANAPIPENAME frogs           # run the 'frogs image reconstruction' stage
  $ $ANAPIPENAME frogs check     # after frogs, check its log and datafiles for problems
  $ $ANAPIPENAME anpar           # run the 'anasum parallel' stage
  $ $ANAPIPENAME anpar check     # after anpar, check its log and datafiles for problems
  $ $ANAPIPENAME mutate          # after anpar, convert anasum parallel files to ctool's fits format
  $ $ANAPIPENAME mutate check    # after anpar, check the mutate stage's log and datafiles
  $ $ANAPIPENAME anmer           # after anpar, merge the anasum parallel files to one anasum file

Other commands:
  $ $ANAPIPENAME options         # print descriptions of all analysis options ('settings' also works)
  $ $ANAPIPENAME options_browser # display the options in a fancy webpage, with the browser set by 'export PIPELINE_BROWSER=/path/to/browser'
  $ $ANAPIPENAME newconfig       # create a new (blank) analysis.config file, will refuse to overwrite any existing one
  $ $ANAPIPENAME jobs            # show progress of all of this project's jobs, updating every 90 seconds, until all jobs are done
  $ $ANAPIPENAME kill            # halt all of this project's jobs
"
	exit 1
fi

exec 5>&1 # extra place to duplicate output to stdout, look for >&5


STAGE=$1
CHK=$2
if [ "$CHK" = "check" ] ; then
	CHECKFLAG=true
else
	CHECKFLAG=false
fi

SETTINGSFILE="analysis.config"

if [ "$STAGE" = "newconfig" ] ; then
	if [ -f "$SETTINGSFILE" ] ; then
		echo "Error, config file '$SETTINGSFILE' already exists.  Please move or rename the existing one before creating a new '$SETTINGSFILE' file.  Exiting..." 2>&1
		exit 1
	else
		BASHPATH=$( which bash )

		echo "#!${BASHPATH}"                              >> "$SETTINGSFILE"
		echo "export RUNLIST=\"YourRunlistFileNameHere\"" >> "$SETTINGSFILE"
		echo "export CUTS=\"Moderate\"                  " >> "$SETTINGSFILE"
		echo "export BACKGROUND=\"reflected\"           " >> "$SETTINGSFILE"
		
		echo
		echo "Now creating '$SETTINGSFILE' for you... done."
		echo
		echo "You should now edit '$SETTINGSFILE' to contain your runlist"
		echo "  filename, your anasum parameter file (RUNPARAMFILE), and any"
		echo "  other options you want in your analysis."
		echo
		echo "All options can be shown by doing '$ $ANAPIPENAME options'"
		echo
	fi
	
	exit 0
fi

function colorOutput {
	
	local OPTLINES="$1"

	# check for color settings, don't print color text if 'noptions' is in SCIPIPE_COLOROPT
	if [[ "$SCIPIPE_COLOROPT" =~ nooptions ]] ; then
		OPTREDD=''
		OPTBLUE=''
		OPTGREE=''
		OPTNORM=''
	else
		OPTREDD='\033[22;31m'
		OPTBLUE='\033[22;34m'
		OPTGREE='\033[22;32m'
		OPTNORM='\033[0m'
	fi

	# parse and color the options text, optimized for the terminal
	while read -r line ; do
		#echo "line: '$line'"
		# if the line starts with a comment '#', make it blue, otherwise print the line green
		if [[ "$line" =~ ^#%[[:space:]] ]] ; then
			continue
		elif [[ "$line" =~ ^## ]] ; then 
			line2=$( echo "$line" | sed -E 's/^##/#/' )
			echo -e "${OPTREDD}${line2}${OPTNORM}"
		elif [[ "$line" =~ ^# ]] ; then
			echo -e "${OPTBLUE}${line}${OPTNORM}"
		else
			echo -e "${OPTGREE}${line}${OPTNORM}"
		fi
	done <<< "$OPTLINES"

}

# settings file, any settings in this file will override the above settings
if [ -f "$SETTINGSFILE" ] ; then
	echo "Loading additional pipeline settings from '$SETTINGSFILE'..."
	source "$SETTINGSFILE"
fi

# check that $EVNDISPSYS is sane
if [ ! -d "$EVNDISPSYS" ] ; then
	echo "error, \$EVNDISPSYS='$EVNDISPSYS' isn't a valid directory, exiting..." 2>&1
	exit 1
fi

# check that $VERITAS_EVNDISP_AUX_DIR is sane
if [ ! -d "$VERITAS_EVNDISP_AUX_DIR" ] ; then
	echo "error, \$VERITAS_EVNDISP_AUX_DIR='$VERITAS_EVNDISP_AUX_DIR' isn't a valid directory, exiting..." 2>&1
	exit 1
fi

# render the runlist filename to its full pathname
RUNLIST=$( readlink -m $RUNLIST )

# check that the runlist is sane
if [ ! -e "$RUNLIST" ] ; then
	echo "error, \$RUNLIST=$RUNLIST needs to be a valid file, exiting..." 2>&1
	exit 1
fi

# directory for storing information about stages, jobs, etc
SCIDIR="$CWD/.pipeline"
mkdir -p $SCIDIR

#if [ "$STAGE" = "options" ] ; then
if [[ "$STAGE" =~ (options|opt|options_browser|settings) ]] ; then
	echo
	echo "#######################################################"
	echo "Analysis Options that you can add to '$SETTINGSFILE':"
	echo "#######################################################"

	# print all the lines of this script that are between 
	# the BEGIN ANALYSIS SETTINGS and END ANALYSIS SETTINGS
	# (followed with a number)
	OPTLINES=$( cat "$ANAPIPENAME" | sed -n '/\[BEGIN ANALYSIS SETTINGS [0-9]\+\]/,/\[END ANALYSIS SETTINGS [0-9]\+\]/p' | tail -n +2 | head -n -1)

	# print with colors
	if [[ "$STAGE" =~ (options_browser) ]] ; then
		#$EVNDISPSYS/scripts/VTS/helper_scripts/pipeline_optionsBrowser.py "$OPTLINES"
		$EVNDISPSYS/scripts/VTS/helper_scripts/pipeline_optionsBrowser.sh "$SCIDIR" "$OPTLINES" 
	else
		colorOutput "$OPTLINES"
	fi
	echo
	
	exit 0
fi

# extra functions
source $EVNDISPSYS/scripts/VTS/helper_scripts/pipeline_functions.sh

# evndisp output directory
mkdir -p $EVNDISPOUTPUTDIR

# frogs output directory
mkdir -p $FROGSOUTPUTDIR

# anasum output directory
mkdir -p $ANASUMOUTPUTDIR

# ctools output directory
mkdir -p $CTOOLSDIR

# check that $SCIPIPE_MANUALLASERFILE is a valid
# file in $VERITAS_EVNDISP_AUX_DIR/Calibration
if [[ "$SCIPIPE_MANUALLASER" == "yes" ]] ; then
	if [[ ! -f "$VERITAS_EVNDISP_AUX_DIR/Calibration/$SCIPIPE_MANUALLASERFILE" ]] ; then
		echo -e "${COTRED}Error, you specified 'SCIPIPE_MANUALLASER=yes', but the file specified by 'SCIPIPE_MANUALLASERFILE=$SCIPIPE_MANUALLASERFILE' doesn't seem to exist.  Use 'SCIPIPE_MANUALLASER=no', or figure out the right file for SCIPIPE_MANUALLASERFILE, exiting...${CONORM}"
		exit 1
	fi
fi

# alert the user if they are using SCIPIPE_NEVENTS
function checkForSciPipeNevents {
    if [[ "$SCIPIPE_NEVENTS" =~ ^[0-9]+$ ]] ; then
		echo -e "${COTYELLOW}Warning, \$SCIPIPE_NEVENTS=$SCIPIPE_NEVENTS, not all events will be processed (this variable is set in $SETTINGSFILE)...${CONORM}"
    fi
}

STAGEFILE="$SCIDIR/stage"
RUNNINGJOBS="$SCIDIR/runningjobs" # file containing job numbers from the last action
if [[ "$1" == "jobs" ]] ; then # print run status
    checkIfJobsAreDoneAlt "$RUNNINGJOBS" "$STAGEFILE" 30
fi

if [[ "$1" == "kill" ]] ; then # kill all running jobs
    killJobsInJobfile "$RUNNINGJOBS"
fi


function setupFilteredRunlists {
	if [[ "$SCIPIPE_USEDISP" == "yes" ]] ; then
		#TABLEDISPCODE="ID1"
		METHCODE="DISP"
	else
		#TABLEDISPCODE="ID0"
		METHCODE="GEO"
	fi
	
	#TABLEFILEWINTV4="$VERITAS_EVNDISP_AUX_DIR/Tables/table-${AUXFILE_EVNVER}-${AUXVER_TABLE}-${AUXFILE_SIMDATE}-ATM21-V4-${TABLEDISPCODE}"
	#TABLEFILESUMMV4="$VERITAS_EVNDISP_AUX_DIR/Tables/table-${AUXFILE_EVNVER}-${AUXVER_TABLE}-${AUXFILE_SIMDATE}-ATM22-V4-${TABLEDISPCODE}"
	#TABLEFILEWINTV5="$VERITAS_EVNDISP_AUX_DIR/Tables/table-${AUXFILE_EVNVER}-${AUXVER_TABLE}-${AUXFILE_SIMDATE}-ATM21-V5-${TABLEDISPCODE}"
	#TABLEFILESUMMV5="$VERITAS_EVNDISP_AUX_DIR/Tables/table-${AUXFILE_EVNVER}-${AUXVER_TABLE}-${AUXFILE_SIMDATE}-ATM22-V5-${TABLEDISPCODE}"
	#TABLEFILEWINTV6="$VERITAS_EVNDISP_AUX_DIR/Tables/table-${AUXFILE_EVNVER}-${AUXVER_TABLE}-${AUXFILE_SIMDATE}-ATM21-V6-${TABLEDISPCODE}"
	#TABLEFILESUMMV6="$VERITAS_EVNDISP_AUX_DIR/Tables/table-${AUXFILE_EVNVER}-${AUXVER_TABLE}-${AUXFILE_SIMDATE}-ATM22-V6-${TABLEDISPCODE}"

	TABLEFILEWINTV4="$VERITAS_EVNDISP_AUX_DIR/Tables/table-${AUXFILE_EVNVER}-${AUXVER_TABLE}-${AUXFILE_SIMDATE_GR}-ATM21-V4-$METHCODE"
	TABLEFILESUMMV4="$VERITAS_EVNDISP_AUX_DIR/Tables/table-${AUXFILE_EVNVER}-${AUXVER_TABLE}-${AUXFILE_SIMDATE_GR}-ATM22-V4-$METHCODE"
	TABLEFILEWINTV5="$VERITAS_EVNDISP_AUX_DIR/Tables/table-${AUXFILE_EVNVER}-${AUXVER_TABLE}-${AUXFILE_SIMDATE_GR}-ATM21-V5-$METHCODE"
	TABLEFILESUMMV5="$VERITAS_EVNDISP_AUX_DIR/Tables/table-${AUXFILE_EVNVER}-${AUXVER_TABLE}-${AUXFILE_SIMDATE_GR}-ATM22-V5-$METHCODE"
	TABLEFILEWINTV6="$VERITAS_EVNDISP_AUX_DIR/Tables/table-${AUXFILE_EVNVER}-${AUXVER_TABLE}-${AUXFILE_SIMDATE_CA}-ATM21-V6-$METHCODE"
	TABLEFILESUMMV6="$VERITAS_EVNDISP_AUX_DIR/Tables/table-${AUXFILE_EVNVER}-${AUXVER_TABLE}-${AUXFILE_SIMDATE_GR}-ATM22-V6-$METHCODE"

	RUNLISTSUMMV4="$SCIDIR/runlist.summer.V4"
	RUNLISTWINTV4="$SCIDIR/runlist.winter.V4"
	RUNLISTSUMMV5="$SCIDIR/runlist.summer.V5"
	RUNLISTWINTV5="$SCIDIR/runlist.winter.V5"
	RUNLISTSUMMV6="$SCIDIR/runlist.summer.V6"
	RUNLISTWINTV6="$SCIDIR/runlist.winter.V6"
	cd $EVNDISPSYS/scripts/VTS
	RUNLIST.whichRunsAreAtmosphere.sh s $RUNLIST | RUNLIST.whichRunsAreArrayEpoch.sh 4 > $RUNLISTSUMMV4
	RUNLIST.whichRunsAreAtmosphere.sh w $RUNLIST | RUNLIST.whichRunsAreArrayEpoch.sh 4 > $RUNLISTWINTV4
	RUNLIST.whichRunsAreAtmosphere.sh s $RUNLIST | RUNLIST.whichRunsAreArrayEpoch.sh 5 > $RUNLISTSUMMV5
	RUNLIST.whichRunsAreAtmosphere.sh w $RUNLIST | RUNLIST.whichRunsAreArrayEpoch.sh 5 > $RUNLISTWINTV5
	RUNLIST.whichRunsAreAtmosphere.sh s $RUNLIST | RUNLIST.whichRunsAreArrayEpoch.sh 6 > $RUNLISTSUMMV6
	RUNLIST.whichRunsAreAtmosphere.sh w $RUNLIST | RUNLIST.whichRunsAreArrayEpoch.sh 6 > $RUNLISTWINTV6

  # grisu and care require separate runlists in evndisp stage
  RUNLISTCARE="$SCIDIR/runlist.grisu"
  RUNLISTGRIS="$SCIDIR/runlist.care"
  cat $RUNLISTSUMMV4 >  $RUNLISTGRIS
  cat $RUNLISTWINTV4 >> $RUNLISTGRIS
  cat $RUNLISTSUMMV5 >> $RUNLISTGRIS
  cat $RUNLISTWINTV5 >> $RUNLISTGRIS
  cat $RUNLISTSUMMV6 >> $RUNLISTGRIS
  cat $RUNLISTWINTV6 >  $RUNLISTCARE # only V6 winter gets to use CARE for now

	cd $CWD
}

# make list of run-specific parameter files
PARAMFILELIST="$SCIDIR/paramfilelist.dat"

if [[ -z "$ANRUNLIST" ]] ; then
	ANASUMRUNLIST="$CWD/AnasumRunList.dat"
else
	ANASUMRUNLIST="$ANRUNLIST"
fi
RUNNUMBERS=`cat $RUNLIST`
function makeParamFile {
	
	# only automatically make the anasum runlist if the user specified so in the options
	# otherwise, skip this step
	if [[ -z "$ANRUNLIST" ]] ; then
		rm -rf $PARAMFILELIST
		rm -rf $ANASUMRUNLIST
		# generate basic param files
		#$EVNDISPSYS/scripts/VTS/helper_scripts/pipeline_generateParamFiles.sh "$CUTS" "$GAMHADCUTDATE" "$RADECDATE" "$EFDATE1" "$EFDATE2" "$TABLEDATE" 3 "$USEFROGS" "$RUNLIST" > "$PARAMFILELIST"
		
		# Pack all the settings into a one-line argument.
		# Characters that will break this: if any options have '~' or ':' or ' ' in them, 
		# as these are used as delimiters in this packing technique.
		SETTINGLINE="~CUTS:$CUTS~AUXFILEEVNVER:$AUXFILE_EVNVER~AUXFILESIMDATEGR:$AUXFILE_SIMDATE_GR~AUXFILESIMDATECA:$AUXFILE_SIMDATE_CA~AUXVERRADEC:$AUXVER_RADEC~AUXVEREFFAREA:$AUXVER_EFFAREA~AUXVERTABLE:$AUXVER_TABLE~AUXFILEMINTEL:$AUXFILE_MINTEL~USEFROGS:$USEFROGS~AUXFILESRCEXT:$AUXFILE_SRCEXT~AUXFILEDISP:$SCIPIPE_USEDISP~USETMVABDT:$USETMVABDT~"
		#echo "SETTINGLINE:'$SETTINGLINE'"
		$EVNDISPSYS/scripts/VTS/helper_scripts/pipeline_generateParamFiles.sh "$SETTINGLINE" "$RUNLIST" > "$PARAMFILELIST"
		PARAMEXIT="$?"
		#echo "PARAMEXIT:$PARAMEXIT" # =0 if ok, !=0 if bad things happened
		if [[ "$PARAMEXIT" != "0" ]] ; then # had a problem generating param files
			echoerr "${COTRED}Error, had a problem generating and/or finding some parameter files (see above text), exiting pipeline...$CONORM"
			exit 1
		fi
		
		# now put these filenames in the AnasumRunList format
		# fill AnasumRunList with each run's info
		# GENERATE ANASUMRUNLIST
		#echo "" > $ANASUMRUNLIST
		rm -rf "$ANASUMRUNLIST"
		echo "Making Param File, using $BACKGROUND background method"
		for ARUN in $RUNNUMBERS ; do
			ARCUTSFILE=$(      grep "RUN$ARUN" "$PARAMFILELIST" | grep -oE "\S*ANASUM.GammaHadron\S*" )
			AREFFAREAFILE=$(   grep "RUN$ARUN" "$PARAMFILELIST" | grep -oE "\S*effArea\S*"            )
			ARRADIALACCFILE=$( grep "RUN$ARUN" "$PARAMFILELIST" | grep -oE "\S*radialAcceptance\S*"   ) 
			if [[ -z "$ARCUTSFILE" || -z "$AREFFAREAFILE" || -z "$ARRADIALACCFILE" ]] ; then
				echo -e "${COTRED}Error, couldn't determine an IRF file for Run $ARUN :"
				if [[ -z "$ARCUTSFILE"      ]] ; then echo -e "${COTRED}   GammaHadronCut   File:'$ARCUTSFILE'      $CONORM" ; fi
				if [[ -z "$AREFFAREAFILE"   ]] ; then echo -e "${COTRED}   EffectiveArea    File:'$AREFFAREAFILE'   $CONORM" ; fi
				if [[ -z "$ARRADIALACCFILE" ]] ; then echo -e "${COTRED}   RadialAcceptance File:'$ARRADIALACCFILE' $CONORM" ; fi
				exit 1
			fi

			#ARRADIALACCFILE="imgselAcceptFile.root"
			if [[ $BACKGROUND == ring ]] ; then
				echo "* $ARUN $ARUN 0 $ARCUTSFILE 1 $AREFFAREAFILE $RINGCENT $RINGAREA $ARRADIALACCFILE" >> $ANASUMRUNLIST
			elif [[ $BACKGROUND == refl* ]] ; then
				echo "* $ARUN $ARUN 0 $ARCUTSFILE 2 $AREFFAREAFILE $REFLWOBOFF $REFLMINREG $REFLMAXREG $ARRADIALACCFILE" >> $ANASUMRUNLIST
			else
				echo -e "${COTRED}Error, unrecognized background keyword '$BACKGROUND', must be 'ring' or 'refl', exiting...${CONORM}"
				exit 1
			fi
		done
	fi
}


# take output from qsub commands, and parse it
# for job numbers, usually:
# Your job ##########
# and add it to the runningJobList
function updateRunningJobFile {
    local INPUTDATA="$1"
    local ACTIVEJOBS=$( echo "$QSUBDATA" | grep -oP "JOBID [0-9.-:]+" | awk '{print $2}' )
    rm -rf "$RUNNINGJOBS" ;
    for AJOB in $ACTIVEJOBS ; do
        #echo "updateRunningJobFile: Adding job: $AJOB"
        echo "$AJOB" >> $RUNNINGJOBS
    done
}

function stageBanner {
    
    # assemble the list of stages, which can depend on some settings
    stageList=()
    stageList+=(evndisp)
    stageList+=(mscw)
    if [[ "$USEFROGS" == "yes" ]] ; then
        stageList+=(frogs)
    fi
    stageList+=(anpar)
    stageList+=(anmer)
    
    # the basic border line.  justify some lines to be the 
    # same length as this line
    line="~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
    
    # first displayed line
	echo -e "${COTBLUE}$line$CONORM"

    # show progress through the stages
    echo -en "${COTBLUE} Progress: "
    i=1
    for stg in ${stageList[@]} ; do
        if [[ $stg == $STAGE ]] ; then echo -en "$COTGREEN" ; fi
        echo -en "$stg"
        if [[ $stg == $STAGE ]] ; then echo -en "$COTBLUE" ; fi
        if [ $i != ${#stageList[@]} ] ; then echo -en " -> " ; fi
        i=$((i+1))
    done
    echo -e "$CONORM"

    # middle displayed line
	echo -e "${COTBLUE}${line}${CONORM}"

    # assemble the second banner showing which stage and the action (run/check)
	if $CHECKFLAG ; then
        ACTION="Checking"
	else
        ACTION="Running"
	fi
    BANNER="~~~~ $ACTION the $STAGE Stage "
    echo -en "$COTBLUE"
    
    # pad it out to the same length as $line
    echo -en "$BANNER${line:${#BANNER}}"
    echo -e "$CONORM"
    
    # final displayed line
	echo -e "${COTBLUE}${line}${CONORM}"
}

# check that the submission script has a properly selected job mode (qsub desy, qsub ucla, etc)
SUBCMD=$( $EVNDISPSYS/scripts/VTS/helper_scripts/UTILITY.readSubmissionCommand.sh )
if [[ $SUBCMD == *ERROR* ]] ; then
	echo
	echo $SUBCMD
	echo "Please check that '\$EVNDISPSYS/scripts/VTS/submissionCommands.dat' has a submission command selected with '*', exiting..."
	echo
	exit 1
fi


# test stage for just making the param file, and nothing else
if [[ "$STAGE" == "xxf" ]] ; then
	stageBanner
	echo "\$VERITAS_EVNDISP_AUX_DIR:$VERITAS_EVNDISP_AUX_DIR"
	echo "\$EVNDISPSYS:$EVNDISPSYS"
	makeParamFile
	exit 0
fi

# print out the chunk of this script that describes all
# of the analysis options the user can use


# s1 event display
if [[ "$STAGE" == "evndisp" ]] ; then
	EVNJOBSUB="$SCIDIR/qsubdata.evndisp"
	if ! $CHECKFLAG ; then 
		haltIfAnyJobsAreRunning $RUNNINGJOBS
		stageBanner
		# evndisp #########################################################
		echo "$STAGE" > "$STAGEFILE"
		setupFilteredRunlists
		makeParamFile
    checkForSciPipeNevents
		cd $EVNDISPSYS/scripts/VTS
    if [[ "$DOCALIB" = yes ]] ; then CALIBCODE=1
    else                             CALIBCODE=0 ; fi
    VPM=1 ## on by default
    if [[ "$USEMODEL3D" == "yes" ]] ; then MODEL3D=1
    else                                   MODEL3D=0 ; fi
    
    # new, GRISU/CARE dependent evndisp command:
    QSUBDATA=""
    NRUNS=$( cat $RUNLISTGRIS | wc -l )
    if [ "$NRUNS" -gt "0" ] ; then
      QSUBDATA="$QSUBDATA \n"$( ./ANALYSIS.evndisp.sh $RUNLISTGRIS $EVNDISPOUTPUTDIR $EVNRECONFILE_GR $CALIBCODE $MODEL3D | tee >(cat - >&5) ) ; fi
    NRUNS=$( cat $RUNLISTCARE | wc -l )
    if [ "$NRUNS" -gt "0" ] ; then
      QSUBDATA="$QSUBDATA \n"$( ./ANALYSIS.evndisp.sh $RUNLISTCARE $EVNDISPOUTPUTDIR $EVNRECONFILE_CA $CALIBCODE $MODEL3D | tee >(cat - >&5) ) ; fi

    # old, simulation-independent command
		#QSUBDATA=$(./ANALYSIS.evndisp.sh $RUNLIST $EVNDISPOUTPUTDIR $CALIBCODE $VPM $MODEL3D | tee >(cat - >&5) )
    
		rm -rf "$EVNJOBSUB"
		echo "$QSUBDATA" > "$EVNJOBSUB"
		updateRunningJobFile "$QSUBDATA"
		
	else # check the stage results
		haltIfAnyJobsAreRunning $RUNNINGJOBS
		stageBanner
		# evndisp check #########################################################
        
        # check qsub submission text for problems
        echo -e "${COTBLUE}checking job submission text...${CONORM}"
        checkLogFileForProblems "$EVNJOBSUB" $SCIPIPE_DEBUGREGEX
        echo
        
        # check batch jobs, if we can
        checkBatchJobExits "$EVNJOBSUB" "$RUNLIST"
        echo
        
		QSUBDATA=$(cat "$EVNJOBSUB")
		while read ARUN ; do
			echo ; echo -e "${COBLUE}~~~~~~~~~~~~~~~~" ; echo -e "~~~~~~ Run:$ARUN${CONORM}"
			RUNDATA=$( echo "$QSUBDATA" | grep -P "^RUN $ARUN" )
			SCRIPT=$(  echo "$RUNDATA"  | grep "RUN $ARUN SCRIPT" | awk '{ print $4 }')
            
			OLOG=$(    echo "$RUNDATA"  | grep "RUN $ARUN OLOG"   | awk '{ print $4 }')
            if filenameIsNotHealthy "$OLOG" "OLOG" "$HUMANBATCHSTDOUT" "$EVNJOBSUB"        ; then continue ; fi
			checkLogFileForProblems "$OLOG" $SCIPIPE_DEBUGREGEX
            
			ELOG=$(    echo "$RUNDATA"  | grep "RUN $ARUN ELOG"   | awk '{ print $4 }')
            if filenameIsNotHealthy "$ELOG" "ELOG" "$HUMANBATCHSTDERR" "$EVNJOBSUB"        ; then continue ; fi
			checkLogFileForProblems "$ELOG" $SCIPIPE_DEBUGREGEX
            
            if [ "$DOCALIB" == "yes" ] ; then
                PEDLOG=$(   cat "$OLOG" | grep "RUN$ARUN PEDLOG"   | awk '{ print $3 }' )
                if filenameIsNotHealthy "$PEDLOG" "PEDLOG" "pedestal log file" "$OLOG"        ; then continue ; fi
                checkLogFileForProblems "$PEDLOG" $SCIPIPE_DEBUGREGEX
                
                TZEROLOG=$( cat "$OLOG" | grep "RUN$ARUN TZEROLOG" | awk '{ print $3 }' )
                if filenameIsNotHealthy "$TZEROLOG" "TZEROLOG" "tzero log file" "$OLOG"       ; then continue ; fi
                checkLogFileForProblems "$TZEROLOG" $SCIPIPE_DEBUGREGEX
            fi

            EVNDISPLOG=$(   cat "$OLOG" | grep "RUN$ARUN EVNDISPLOG" | awk '{ print $3 }' )
            if filenameIsNotHealthy "$EVNDISPLOG" "EVNDISPLOG" "evndisp log file" "$OLOG"  ; then continue ; fi
            checkLogFileForProblems "$EVNDISPLOG" $SCIPIPE_DEBUGREGEX
            
            checkLogFileForStageSuccess "$EVNDISPLOG" "Final checks on result file (seems to be OK):"
		done < $RUNLIST
		
		echo ; echo -e "${COBLUE}~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
		OLOG=$( echo "$QSUBDATA" | grep -P "^RUN \d+ OLOG" | head -n 1 | awk '{ print $4 }' )
        if filenameIsNotHealthy "$OLOG" "OLOG" "$HUMANBATCHSTDOUT" "$EVNJOBSUB"        ; then echo -e "${COTRED}Error, Probably can't find datafiles, because we can't find the batch stdout log file...$CONORM" ; fi
        
		DFDIR=$( cat $OLOG | grep -P "^RUN\d{5} EVNDISPLOG" | awk '{ print $3 }' )
		DFDIR=$( dirname $DFDIR )
		echo -e "~~~~~~~~~~~ Evndisp Datafiles stored in $DFDIR/ $CONORM"
		while read ARUN ; do
			RUNDATA=$( echo "$QSUBDATA" | grep -P "^RUN $ARUN" )
            
			OLOG=$(    echo "$RUNDATA"  | grep -P "^RUN $ARUN OLOG" | awk '{ print $4 }' )
            if filenameIsNotHealthy "$OLOG" "OLOG" "$HUMANBATCHSTDOUT" "$EVNJOBSUB"        ; then continue ; fi
            
			ELOG=$(    echo "$RUNDATA"  | grep -P "^RUN $ARUN ELOG" | awk '{ print $4 }' )
            if filenameIsNotHealthy "$ELOG" "ELOG" "$HUMANBATCHSTDERR" "$EVNJOBSUB"        ; then continue ; fi
            
            DATAFILE=$( cat "$OLOG" | grep "RUN$ARUN EVNDISPDATA"  | awk '{ print $3 }' )
            if filenameIsNotHealthy "$DATAFILE" "EVNDISPDATA" "evndisp datafile" "$OLOG"   ; then continue ; fi
            
            if [ "$DOCALIB" == "yes" ] ; then
                PEDLOG=$(   cat "$OLOG" | grep "RUN$ARUN PEDLOG"   | awk '{ print $3 }' )
                if filenameIsNotHealthy "$PEDLOG" "PEDLOG" "pedestal log file"  "$OLOG" ; then continue ; fi
                
                TZEROLOG=$( cat "$OLOG" | grep "RUN$ARUN TZEROLOG" | awk '{ print $3 }' )
                if filenameIsNotHealthy "$TZEROLOG" "TZEROLOG" "tzero log file" "$OLOG" ; then continue ; fi
            fi
            
            EVNDISPLOG=$(   cat "$OLOG" | grep "RUN$ARUN EVNDISPLOG"   | awk '{ print $3 }' )
            if filenameIsNotHealthy "$EVNDISPLOG" "EVNDISPLOG" "evndisp log file" "$OLOG"  ; then continue ; fi
            
            LOGFILES=("$OLOG" "$ELOG" "$EVNDISPLOG" )
            if [ "$DOCALIB" == "yes" ] ; then
                LOGFILES+=( "$PEDLOG" "$TZEROLOG" )
            fi
            WARNCOUNTSTR=$(  formatwarncount  LOGFILES[@] )
            ERRORCOUNTSTR=$( formaterrorcount LOGFILES[@] )
            
            DFBASE=$( basename $DATAFILE )
            DFSIZE=`stat -c %s $DATAFILE`
            DFSIZESTR=$( formatFileSize "$DFSIZE" )
            DFMODDATE=`stat -c %y $DATAFILE | cut -f1 -d.`
            RUNSUCCESS=$( checkForSuccess "$EVNDISPLOG" "Final checks on result file (seems to be OK):")
            printf "%10s is %s, last modified %19s %12s %10s  : %s\n" "$DFBASE" "$DFSIZESTR" "$DFMODDATE" "$WARNCOUNTSTR" "$ERRORCOUNTSTR" "$RUNSUCCESS"
		done < $RUNLIST
		
		exit 0
	fi
fi

# s2 mscw
if [[ "$STAGE" == "mscw" ]] ; then
	MSCWJOBSUB="$SCIDIR/qsubdata.mscw"
	if ! $CHECKFLAG ; then
		haltIfAnyJobsAreRunning $RUNNINGJOBS
		stageBanner
		# mscw #########################################################
		echo "$STAGE" > "$STAGEFILE"
    checkForSciPipeNevents
		setupFilteredRunlists
		makeParamFile
		cd $EVNDISPSYS/scripts/VTS
        
        # convert energy3d code
        if [[ $USEENERGY3D == "yes" ]] ; then ENERGY3D=1 ;
        else                                  ENERGY3D=0 ;
        fi

		#./VTS.MSCW_ENERGY.sub_analyse_data.sh $TABLEFILE $EVNDISPOUTPUTDIR $RUNLIST
		QSUBDATA=""
		NRUNS=$( cat $RUNLISTWINTV4 | wc -l )
		if [ "$NRUNS" -gt "0" ] ; then
			QSUBDATA="$QSUBDATA \n"$( ./ANALYSIS.mscw_energy.sh $TABLEFILEWINTV4 $RUNLISTWINTV4 "$EVNDISPOUTPUTDIR" $RECID "${EVNDISPOUTPUTDIR}/RecID${RECID}" "$ENERGY3D" | tee >(cat ->&5) ) ; fi
		NRUNS=$( cat $RUNLISTSUMMV4 | wc -l )
		if [ "$NRUNS" -gt "0" ] ; then
			QSUBDATA="$QSUBDATA \n"$( ./ANALYSIS.mscw_energy.sh $TABLEFILESUMMV4 $RUNLISTSUMMV4 "$EVNDISPOUTPUTDIR" $RECID "${EVNDISPOUTPUTDIR}/RecID${RECID}" "$ENERGY3D" | tee >(cat ->&5) ) ; fi
		NRUNS=$( cat $RUNLISTWINTV5 | wc -l )
		if [ "$NRUNS" -gt "0" ] ; then
			QSUBDATA="$QSUBDATA \n"$( ./ANALYSIS.mscw_energy.sh $TABLEFILEWINTV5 $RUNLISTWINTV5 "$EVNDISPOUTPUTDIR" $RECID "${EVNDISPOUTPUTDIR}/RecID${RECID}" "$ENERGY3D" | tee >(cat ->&5) ) ; fi
		NRUNS=$( cat $RUNLISTSUMMV5 | wc -l )
		if [ "$NRUNS" -gt "0" ] ; then
			QSUBDATA="$QSUBDATA \n"$( ./ANALYSIS.mscw_energy.sh $TABLEFILESUMMV5 $RUNLISTSUMMV5 "$EVNDISPOUTPUTDIR" $RECID "${EVNDISPOUTPUTDIR}/RecID${RECID}" "$ENERGY3D" | tee >(cat ->&5) ) ; fi
		NRUNS=$( cat $RUNLISTWINTV6 | wc -l )
		if [ "$NRUNS" -gt "0" ] ; then
			QSUBDATA="$QSUBDATA \n"$( ./ANALYSIS.mscw_energy.sh $TABLEFILEWINTV6 $RUNLISTWINTV6 "$EVNDISPOUTPUTDIR" $RECID "${EVNDISPOUTPUTDIR}/RecID${RECID}" "$ENERGY3D" | tee >(cat ->&5) ) ; fi
		NRUNS=$( cat $RUNLISTSUMMV6 | wc -l )
		if [ "$NRUNS" -gt "0" ] ; then
			QSUBDATA="$QSUBDATA \n"$( ./ANALYSIS.mscw_energy.sh $TABLEFILESUMMV6 $RUNLISTSUMMV6 "$EVNDISPOUTPUTDIR" $RECID "${EVNDISPOUTPUTDIR}/RecID${RECID}" "$ENERGY3D" | tee >(cat ->&5) ) ; fi

export USEENERGY3D="no"
		rm -rf "$MSCWJOBSUB"
		echo "$QSUBDATA" > "$MSCWJOBSUB"
		updateRunningJobFile "$QSUBDATA"
	else
		haltIfAnyJobsAreRunning $RUNNINGJOBS
		stageBanner
		# mscw check #########################################################
        
        # check qsub submission text for problems
        echo -e "${COTBLUE}checking job submission text...${CONORM}"
        checkLogFileForProblems "$MSCWJOBSUB" $SCIPIPE_DEBUGREGEX
        echo
        
        # check batch jobs, if we can
        checkBatchJobExits "$MSCWJOBSUB" "$RUNLIST"
        echo
        
		QSUBDATA=$(cat "$MSCWJOBSUB")
		while read ARUN ; do
			echo ; echo -e "${COBLUE}~~~~~~~~~~~~~~~~~~~~~" ; echo -e "~~~~~~~~~~~ Run:$ARUN${CONORM}"
			RUNDATA=$( echo "$QSUBDATA" | grep -P "^RUN $ARUN" )
			SCRIPT=$(  echo "$RUNDATA"  | grep "RUN $ARUN SCRIPT" | awk '{ print $4 }' )
            
			OLOG=$(    echo "$RUNDATA"  | grep "RUN $ARUN OLOG"   | awk '{ print $4 }' )
            if filenameIsNotHealthy "$OLOG" "OLOG" "$HUMANBATCHSTDOUT" "$MSCWJOBSUB"        ; then continue ; fi
			checkLogFileForProblems "$OLOG" $SCIPIPE_DEBUGREGEX
            
			ELOG=$(    echo "$RUNDATA"  | grep "RUN $ARUN ELOG"   | awk '{ print $4 }' )
            if filenameIsNotHealthy "$ELOG" "ELOG" "$HUMANBATCHSTDERR" "$EVNJOBSUB"        ; then continue ; fi
			checkLogFileForProblems "$ELOG" $SCIPIPE_DEBUGREGEX
            
            MSCWLOG=$(   cat "$OLOG" | grep "RUN$ARUN MSCWLOG"   | awk '{ print $3 }' )
            if filenameIsNotHealthy "$MSCWLOG" "MSCWLOG" "mscw log file" "$OLOG"  ; then continue ; fi
            checkLogFileForProblems "$MSCWLOG" $SCIPIPE_DEBUGREGEX
            
            checkLogFileForStageSuccess "$MSCWLOG" "...outputfile closed"
		done < $RUNLIST

		OLOG=$(  echo "$QSUBDATA" | grep -P "^RUN \d+ OLOG"    | head -n 1 | awk '{ print $4 }' )
		DFDIR=$( cat $OLOG        | grep -P "^RUN\d{5} MSCWLOG" | awk '{ print $3 }' )
		DFDIR=$( dirname $DFDIR )
		echo
		echo -e "${COBLUE}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
		echo -e "~~~~~~~~~~~ MSCW Datafiles stored in $DFDIR/$CONORM"
		while read ARUN ; do
			RUNDATA=$( echo "$QSUBDATA" | grep -P "^RUN $ARUN" )
            
			OLOG=$(     echo "$RUNDATA"  | grep "RUN $ARUN OLOG"     | awk '{ print $4 }' )
            if filenameIsNotHealthy "$OLOG" "OLOG" "$HUMANBATCHSTDOUT" "$MSCWJOBSUB" ; then continue ; fi
            
			ELOG=$(     echo "$RUNDATA"  | grep "RUN $ARUN ELOG"     | awk '{ print $4 }' )
            if filenameIsNotHealthy "$ELOG" "ELOG" "$HUMANBATCHSTDERR" "$MSCWJOBSUB" ; then continue ; fi
            
            MSCWLOG=$(  cat "$OLOG"      | grep "RUN$ARUN MSCWLOG"  | awk '{ print $3 }' )
            if filenameIsNotHealthy "$MSCWLOG"  "MSCWLOG"  "mscw log file" "$OLOG"   ; then continue ; fi
            
            DATAFILE=$( cat "$OLOG"      | grep "RUN$ARUN MSCWDATA" | awk '{ print $3 }' )
            if filenameIsNotHealthy "$DATAFILE" "MSCWDATA" "mscw datafile" "$OLOG"   ; then continue ; fi
            
            LOGFILES=("$OLOG" "$ELOG" "$MSCWLOG" )
            WARNCOUNTSTR=$(  formatwarncount  LOGFILES[@] )
            ERRORCOUNTSTR=$( formaterrorcount LOGFILES[@] )
            
            DFBASE=$( basename $DATAFILE )
            DFSIZE=`stat -c %s $DATAFILE`
            DFSIZESTR=$( formatFileSize "$DFSIZE" )
            DFMODDATE=`stat -c %y $DATAFILE | cut -f1 -d.`
            RUNSUCCESS=$( checkForSuccess "$MSCWLOG" "...outputfile closed" )
            printf "%10s is %s, last modified %19s %12s %10s  : %s\n" "$DFBASE" "$DFSIZESTR" "$DFMODDATE" "$WARNCOUNTSTR" "$ERRORCOUNTSTR" "$RUNSUCCESS"
		done < $RUNLIST
	fi
fi

# s3 frogs 
if [[ "$STAGE" == "frogs" ]] ; then
    FROGSJOBSUB="$SCIDIR/qsubdata.frogs"
	if ! $CHECKFLAG ; then
		haltIfAnyJobsAreRunning $RUNNINGJOBS
		stageBanner
		# frogs #################################################################
		echo "$STAGE" > "$STAGEFILE"
		cd $EVNDISPSYS/scripts/VTS
        checkForSciPipeNevents
		setupFilteredRunlists
		makeParamFile
        
        # frogs ########################################################
		QSUBDATA=$( ./ANALYSIS.evndisp_frogs.sh "$RUNLIST" "$FROGSOUTPUTDIR" "$EVNDISPOUTPUTDIR/RecID${RECID}" 0 | tee >(cat - >&5) )
		
		updateRunningJobFile "$QSUBDATA"
		rm -rf "$FROGSJOBSUB"
        echo "$QSUBDATA" > "$FROGSJOBSUB"
        sleep 2
	else
		haltIfAnyJobsAreRunning $RUNNINGJOBS
		stageBanner
		# frogs check #########################################################
        
        # check qsub submission text for problems
        echo -e "${COTBLUE}checking job submission text...${CONORM}"
        checkLogFileForProblems "$FROGSJOBSUB" $SCIPIPE_DEBUGREGEX
        echo
        
        # check batch jobs, if we can
        checkBatchJobExits "$FROGSJOBSUB" "$RUNLIST"
        
        # scan all log files
        QSUBDATA=$( cat $FROGSJOBSUB )
		while read ARUN ; do
            echo
			echo -e "${COBLUE}~~~~~~~~~~~~~~~~" ; echo -e "~~~~~~ Run:$ARUN${CONORM}"
			RUNDATA=$( echo "$QSUBDATA" | grep -P "^RUN $ARUN" )
			SCRIPT=$(  echo "$RUNDATA"  | grep "RUN $ARUN SCRIPT" | awk '{ print $4 }' )
            
			OLOG=$(    echo "$RUNDATA"  | grep "RUN $ARUN OLOG"   | awk '{ print $4 }' )
            if filenameIsNotHealthy "$OLOG" "OLOG" "$HUMANBATCHSTDOUT" "$FROGSJOBSUB"        ; then continue ; fi
			checkLogFileForProblems "$OLOG" $SCIPIPE_DEBUGREGEX
            
			ELOG=$(    echo "$RUNDATA"  | grep "RUN $ARUN ELOG"   | awk '{ print $4 }' )
            if filenameIsNotHealthy "$ELOG" "ELOG" "$HUMANBATCHSTDERR" "$FROGSJOBSUB"        ; then continue ; fi
			checkLogFileForProblems "$ELOG" $SCIPIPE_DEBUGREGEX
            
            FROGSLOG=$( cat "$OLOG" | grep "RUN$ARUN FROGSLOG"  | awk '{ print $3 }' )
            if filenameIsNotHealthy "$FROGSLOG" "FROGSLOG" "frogs log file" "$OLOG"  ; then continue ; fi
            checkLogFileForProblems "$FROGSLOG" $SCIPIPE_DEBUGREGEX
            
            checkLogFileForStageSuccess "$FROGSLOG" "Final checks on result file (seems to be OK)"
		done < $RUNLIST

		OLOG=$(  echo "$QSUBDATA" | grep -P "^RUN \d+ OLOG"     | head -n 1 | awk '{ print $4 }' )
		DFDIR=$( cat $OLOG        | grep -P "^RUN\d+ FROGSLOG" | awk '{ print $3 }' )
		DFDIR=$( dirname $DFDIR )
		echo
		echo -e "${COBLUE}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
		echo -e "~~~~~~~~~~~ FROGS Datafiles stored in $DFDIR/$CONORM"
		while read ARUN ; do
			RUNDATA=$( echo "$QSUBDATA" | grep -P "^RUN $ARUN" )
            
			OLOG=$(     echo "$RUNDATA"  | grep "RUN $ARUN OLOG"      | awk '{ print $4 }' )
            if filenameIsNotHealthy "$OLOG"     "OLOG"      "$HUMANBATCHSTDOUT" "$FROGSJOBSUB" ; then continue ; fi
            
			ELOG=$(     echo "$RUNDATA"  | grep "RUN $ARUN ELOG"      | awk '{ print $4 }' )
            if filenameIsNotHealthy "$ELOG"     "ELOG"      "$HUMANBATCHSTDERR" "$FROGSJOBSUB" ; then continue ; fi
            
            DATAFILE=$( cat "$OLOG"      | grep "RUN$ARUN FROGSDATA" | awk '{ print $3 }' )
            if filenameIsNotHealthy "$DATAFILE" "FROGSDATA" "frogs datafile"    "$OLOG"        ; then continue ; fi
            
            FROGSLOG=$( cat "$OLOG"      | grep "RUN$ARUN FROGSLOG"  | awk '{ print $3 }' )
            if filenameIsNotHealthy "$FROGSLOG" "FROGSLOG"  "frogs log file"    "$OLOG"        ; then continue ; fi
            
            LOGFILES=("$OLOG" "$ELOG" "$FROGSLOG" )
            WARNCOUNTSTR=$(  formatwarncount  LOGFILES[@] )
            ERRORCOUNTSTR=$( formaterrorcount LOGFILES[@] )
            
            DFBASE=$( basename $DATAFILE )
            DFSIZE=`stat -c %s $DATAFILE`
            DFSIZESTR=$( formatFileSize "$DFSIZE" )
            DFMODDATE=`stat -c %y $DATAFILE | cut -f1 -d.`
            RUNSUCCESS=$( checkForSuccess "$FROGSLOG" "Final checks on result file (seems to be OK)" )
            printf "%10s is %s, last modified %19s %12s %10s  : %s\n" "$DFBASE" "$DFSIZESTR" "$DFMODDATE" "$WARNCOUNTSTR" "$ERRORCOUNTSTR" "$RUNSUCCESS"
		done < $RUNLIST
	fi
fi

# s4 anasum_parallel (anpar)
if [[ "$STAGE" == "anpar" ]] ; then
	ANPARJOBSUB="$SCIDIR/qsubdata.anpar"
	if ! $CHECKFLAG ; then
		haltIfAnyJobsAreRunning $RUNNINGJOBS
		stageBanner
		# anpar #########################################################
		makeParamFile
		echo "$STAGE" > "$STAGEFILE"
        checkForSciPipeNevents
		cd $EVNDISPSYS/scripts/VTS
		
		# decide input directory
        if [[ "$USEFROGS" == "yes" ]] ; then 
            INPUTANASUMDIR="$FROGSOUTPUTDIR"
            echo -e "${COTYELLOW}Using frogs files as input...$CONORM"
        else
            INPUTANASUMDIR="$EVNDISPOUTPUTDIR/RecID${RECID}"
            echo -e "Using mscw files as input..."
        fi
		
		QSUBDATA=$( ./ANALYSIS.anasum_parallel.sh "$ANASUMRUNLIST" "$INPUTANASUMDIR" "$ANASUMOUTPUTDIR" "$RUNPARAMFILE" | tee >(cat - >&5) )
		updateRunningJobFile "$QSUBDATA"
		rm -rf "$ANPARJOBSUB"
        echo "$QSUBDATA" > "$ANPARJOBSUB"
        sleep 2
	else
		haltIfAnyJobsAreRunning $RUNNINGJOBS
		stageBanner
		# anpar check #########################################################
        
        # check qsub submission text for problems
        echo -e "${COTBLUE}checking job submission text...${CONORM}"
        checkLogFileForProblems "$ANPARJOBSUB" $SCIPIPE_DEBUGREGEX
        echo
        
        # check batch jobs, if we can
        checkBatchJobExits "$ANPARJOBSUB" "$RUNLIST"
        echo
        
		QSUBDATA=$( cat $ANPARJOBSUB )
		for ARUN in $RUNNUMBERS ; do # check batch and log files
			echo ; echo -e "${COBLUE}~~~~~~~~~~~~~~~~~~~~~" ; echo -e "~~~~~~~~~~~ Run:$ARUN${CONORM}"
			RUNDATA=$( echo "$QSUBDATA" | grep -P "^RUN $ARUN" )
			SCRIPT=$(  echo "$RUNDATA"  | grep "RUN $ARUN SCRIPT" | awk '{ print $4 }' )
            
			OLOG=$( echo "$RUNDATA" | grep "RUN $ARUN OLOG" | awk '{ print $4 }' )
            if filenameIsNotHealthy "$OLOG" "OLOG" "$HUMANBATCHSTDOUT" "$ANPARJOBSUB" ; then continue ; fi
			checkLogFileForProblems "$OLOG" $SCIPIPE_DEBUGREGEX
            
			ELOG=$( echo "$RUNDATA" | grep "RUN $ARUN ELOG" | awk '{ print $4 }' )
			checkLogFileForProblems "$ELOG" $SCIPIPE_DEBUGREGEX
            if filenameIsNotHealthy "$ELOG" "ELOG" "$HUMANBATCHSTDERR" "$ANPARJOBSUB" ; then continue ; fi
            
            ANPARLOG=$( cat "$OLOG" | grep "RUN$ARUN ANPARLOG" | awk '{ print $3 }' )
            if filenameIsNotHealthy "$ANPARLOG" "ANPARLOG" "anasum parallel log file" "$OLOG" ; then continue ; fi
            checkLogFileForProblems "$ANPARLOG" $SCIPIPE_DEBUGREGEX
             
            checkLogFileForStageSuccess "$ANPARLOG" "analysis results written to"
		done < $RUNLIST
		
		OLOG=$(  echo "$QSUBDATA" | grep -P "^RUN \d+ OLOG"     | head -n 1 | awk '{ print $4 }' )
		DFDIR=$( cat $OLOG        | grep -P "^RUN\d{5} ANPARLOG" | awk '{ print $3 }' )
		DFDIR=$( dirname $DFDIR )
		echo ; echo -e "${COBLUE}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
		echo -e "~~~~~~~~~~~ ANASUM Datafiles stored in $DFDIR/$CONORM"
		while read ARUN ; do
			RUNDATA=$( echo "$QSUBDATA" | grep -P "^RUN $ARUN" )
            
			OLOG=$(    echo "$RUNDATA"  | grep "RUN $ARUN OLOG"   | awk '{ print $4 }')
            if filenameIsNotHealthy "$OLOG" "OLOG" "$HUMANBATCHSTDOUT" "$ANPARJOBSUB"        ; then continue ; fi
            
            ANPARLOG=$(  cat "$OLOG" | grep "RUN$ARUN ANPARLOG"  | awk '{ print $3 }' )
            if filenameIsNotHealthy "$ANPARLOG" "ANPARLOG" "anasum parallel log file" "$OLOG"  ; then continue ; fi
            
            DATAFILE=$(  cat "$OLOG" | grep "RUN$ARUN ANPARDATA"   | awk '{ print $3 }' )
            if filenameIsNotHealthy "$DATAFILE" "ANPARDATA" "anasum parallel datafile" "$OLOG"   ; then continue ; fi
            
            LOGFILES=("$OLOG" "$ELOG" "$ANPARLOG" )
            WARNCOUNTSTR=$(  formatwarncount  LOGFILES[@] )
            ERRORCOUNTSTR=$( formaterrorcount LOGFILES[@] )
            RUNSIGMA=$( grep -E "ALL RUNS" "$ANPARLOG" | grep -oP '\d{1,3}\.\d{0,2} sigma' | grep -oP '\d{1,3}\.\d{0,2}')
            
            DFBASE=$( basename $DATAFILE )
            DFSIZE=`stat -c %s $DATAFILE`
            DFSIZESTR=$( formatFileSize "$DFSIZE" )
            DFMODDATE=`stat -c %y $DATAFILE | cut -f1 -d.`
            RUNSUCCESS=$( checkForSuccess "$ANPARLOG" "analysis results written to" )
            printf "%10s is %s, last modified %19s sigma=%5s %12s %11s  : %s\n" "$DFBASE" "$DFSIZESTR" "$DFMODDATE" "$RUNSIGMA" "$WARNCOUNTSTR" "$ERRORCOUNTSTR" "$RUNSUCCESS"
            
		done < $RUNLIST

	fi
fi

# s5 anasum
if [[ "$STAGE" == "anmer" ]] ; then
	FINALOUTPUTLOG="${ANASUMOUTPUTDIR}/`basename $FINALOUTPUT .root`.log"
	if ! $CHECKFLAG ; then
		haltIfAnyJobsAreRunning $RUNNINGJOBS
		stageBanner
		# anmer #############################################################################
		makeParamFile
		echo "$STAGE" > "$STAGEFILE"
		cd $EVNDISPSYS/scripts/VTS
		nice -n 19 ./ANALYSIS.anasum_combine.sh $ANASUMRUNLIST $ANASUMOUTPUTDIR $FINALOUTPUT $RUNPARAMFILE | tee "$FINALOUTPUTLOG"
		updateRunningJobFile ""
     
    else
		haltIfAnyJobsAreRunning $RUNNINGJOBS
		stageBanner
		# anmer check ######################################################################
        if filenameIsNotHealthy "$FINALOUTPUTLOG" "(filename constructed in ANALYSIS.pipeline)" "merged anasum log file" "ANALYSIS.pipeline"  ; then continue ; fi
		checkLogFileForProblems $FINALOUTPUTLOG $SCIPIPE_DEBUGREGEX
        
		DATAFILE="${ANASUMOUTPUTDIR}/${FINALOUTPUT}"
        if filenameIsNotHealthy "$DATAFILE" "FINALOUTPUT" "merge anasum datafile" "ANALYSIS.pipeline"  ; then continue ; fi
        
        LOGFILES=( "$FINALOUTPUTLOG" )
        WARNCOUNTSTR=$(  formatwarncount  LOGFILES[@] )
        ERRORCOUNTSTR=$( formaterrorcount LOGFILES[@] )
        RUNSIGMA=$( grep -E "ALL RUNS" "$FINALOUTPUTLOG" | grep -oP '\d{1,3}\.\d{0,2} sigma' | grep -oP '\d{1,3}\.\d{0,2}')
        
        DFBASE=$( basename $DATAFILE )
        DFSIZE=`stat -c %s $DATAFILE`
        DFSIZESTR=$( formatFileSize "$DFSIZE" )
        DFMODDATE=`stat -c %y $DATAFILE | cut -f1 -d.`
        printf "%10s is %s, last modified %19s sigma=%5s %12s %11s  : %s\n" "$DFBASE" "$DFSIZESTR" "$DFMODDATE" "$RUNSIGMA" "$WARNCOUNTSTR" "$ERRORCOUNTSTR" "$RUNSUCCESS"
	fi
fi

# s6 mutate : (convert) Anasum Parallel files to CTOOL's Data Format$
if [[ "$STAGE" == "mutate" ]] ; then
	if ! $CHECKFLAG ; then
		haltIfAnyJobsAreRunning $RUNNINGJOBS
		stageBanner
		
		# check that anasum run parameter file has the WRITEEVENTTREEFORCTOOLS
		GOODSETTING=$( cat "$RUNPARAMFILE" | grep -P "^\*\s+WRITEEVENTTREEFORCTOOLS\s+1")
		if [ -z "$GOODSETTING" ] ; then
			echo -e "${COTYELLOW}Warning, you're trying to convert anasum files to ctool's fits format, but ${COTRED}these anasum files may not have been made with the '* WRITEEVENTTREEFORCTOOLS 1' option${COTYELLOW} in its Anasum Parameter File: '$RUNPARAMFILE'${CONORM}"
			echo -e "${COTYELLOW}  There is a very good chance this stage will fail.$CONORM"
		fi
		
        
		# mutate ###################################################3
        cd $EVNDISPSYS/bin
        echo "now here: $PWD"
        echo "output data going here: $CTOOLSDIR"
        while read ARUN ; do
            # this stage runs quite fast (~10seconds per run)
            # so we wont run it in parallel
            #echo "$ANASUMOUTPUTDIR/$ARUN.anasum.root"
            echo "Producing $CTOOLSDIR/$ARUN.ctools.fits ..."
            writeCTAEventListFromAnasum -f -i "$ANASUMOUTPUTDIR/$ARUN.anasum.root" -o "$CTOOLSDIR/$ARUN.ctools.fits" >  "$CTOOLSDIR/$ARUN.ctools.log" 2>&1  
            #echo
        done < $RUNLIST
        
    else
		haltIfAnyJobsAreRunning $RUNNINGJOBS
		stageBanner
		# mutate check ###################################################3
        
        # check log files
        while read ARUN ; do
			echo ; echo -e "${COBLUE}~~~~~~~~~~~~~~~~~~~~~" ; echo -e "~~~~~~~~~~~ Run:$ARUN${CONORM}"
            CTOOLSLOG="$CTOOLSDIR/$ARUN.ctools.log"
            checkLogFileForProblems     "$CTOOLSLOG" $SCIPIPE_DEBUGREGEX
            checkLogFileForStageSuccess "$CTOOLSLOG" "Conversion from .* complete"
        done < $RUNLIST
        
        # check data files
		echo ; echo -e "${COBLUE}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
		echo -e "~~~~~~~~~~~ CTOOLS Datafiles stored in $CTOOLSDIR/$CONORM"
        while read ARUN ; do
            LOGFILES=("$CTOOLSDIR/$ARUN.ctools.log" )
            WARNCOUNTSTR=$(  formatwarncount  LOGFILES[@] )
            ERRORCOUNTSTR=$( formaterrorcount LOGFILES[@] )
            
            DATAFILE="$CTOOLSDIR/$ARUN.ctools.fits"
            DFBASE=$( basename $DATAFILE )
            DFSIZE=`stat -c %s $DATAFILE`
            DFSIZESTR=$( formatFileSize "$DFSIZE" )
            DFMODDATE=`stat -c %y $DATAFILE | cut -f1 -d.`
            NEVENTS=$( cat "$CTOOLSDIR/$ARUN.ctools.log" | grep -P "RunNumber \d+, \d+ events written." | grep -oP ", \d+ events" | grep -oP "\d+" )
            RUNSUCCESS=$( checkForSuccess "$CTOOLSDIR/$ARUN.ctools.log" "Conversion from .* complete" )
            printf "%10s is %s, last modified %19s events=%5s %12s %11s  : %s\n" "$DFBASE" "$DFSIZESTR" "$DFMODDATE" "$NEVENTS" "$WARNCOUNTSTR" "$ERRORCOUNTSTR" "$RUNSUCCESS"
        done < $RUNLIST
    fi
fi
